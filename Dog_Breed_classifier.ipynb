{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNO58eyR9DPEidKIzPdiTQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PARAS759/Dog-Breed-identification/blob/main/Dog_Breed_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kbyzOh_0crS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AbhPqX-Z6g7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tqdm.autonotebook import tqdm\n",
        "from keras import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import Lambda, Input , GlobalAveragePooling2D , BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "6O-U-O1v6g-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU\", \"available (YESS!!!)\" if tf.config.list_physical_devices(\"GPU\") else (\"not available\"))\n",
        "tf.config.list_physical_devices(\"GPU\")"
      ],
      "metadata": {
        "id": "7tjbDH0A6hC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('/content/drive/MyDrive/Data/dog-breed-identification/labels.csv')\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "LFLINq6B6hF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.describe()"
      ],
      "metadata": {
        "id": "XmVQrWhg6hJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to show bar length\n",
        "# def barw(ax):\n",
        "#   for p in ax.patches:\n",
        "#     val = p.get_width()\n",
        "#     x = p.get_x()+ p.get_width()\n",
        "#     y = p.get_y() + p.get_height()\n",
        "#     ax.annotate(round(val,2),(x,y))\n",
        "\n",
        "# # finding top dog brand\n",
        "# plt.figure(figsize = (15,30))\n",
        "# ax0 = sns.countplot(y = labels['breed'],order = labels['breed'].value_counts().index)\n",
        "# barw(ax0)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "KYl2_VZE6hUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import display, Image\n",
        "# Image('/content/drive/MyDrive/Data/dog-breed-identification/train/002211c81b498ef88e1b40b9abf84e1d.jpg')\n",
        "# Image('/content/drive/MyDrive/Data/dog-breed-identification/train/0067dc3eab0b3c3ef0439477624d85d6.jpg')"
      ],
      "metadata": {
        "id": "f7rBGecB6hW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if len(os.listdir('/content/drive/MyDrive/Data/dog-breed-identification/train'))==len(labels['id']):\n",
        "#   print(\"Number of files and images are equal\")\n",
        "# else:\n",
        "#   print('Not equal files and images')"
      ],
      "metadata": {
        "id": "ulF5TDhG6hZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes  = sorted(list(set(labels['breed'])))\n",
        "n_classes = len(classes)\n",
        "# print('Total unique breed {}'.format(n_classes))\n",
        "\n",
        "# Mappint each label string to an intefer label\n",
        "class_to_num = dict(zip(classes , range(n_classes)))\n",
        "class_to_num"
      ],
      "metadata": {
        "id": "QsJnEBDQ6hcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (250,250,3)\n",
        "\n",
        "def images_to_array(directory , label_dataframe , target_size = input_shape):\n",
        "\n",
        "  image_labels = label_dataframe['breed']\n",
        "  images = np.zeros([len(label_dataframe) , target_size[0] , target_size[1] , target_size[2]],dtype = np.uint8)\n",
        "  y = np.zeros([len(label_dataframe) , 1] , dtype = np.uint8)\n",
        "\n",
        "  for ix,image_name in enumerate(tqdm(label_dataframe['id'].values)):\n",
        "    img_dir = os.path.join(directory, image_name + '.jpg')\n",
        "    img = load_img(img_dir,target_size = target_size)\n",
        "    images[ix] = img\n",
        "    del img\n",
        "    dog_breed = image_labels[ix]\n",
        "    y[ix] = class_to_num[dog_breed]\n",
        "  y = to_categorical(y)\n",
        "  return images,y\n"
      ],
      "metadata": {
        "id": "FeT543g36he8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "t = time.time()\n",
        "\n",
        "X,y = images_to_array('/content/drive/MyDrive/Data/dog-breed-identification/train',labels[:])\n",
        "print('runtime in seconds : {}'.format(time.time()-t))"
      ],
      "metadata": {
        "id": "0OXg4ixu6hiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(X))"
      ],
      "metadata": {
        "id": "trtXbYwcemiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n = 25\n",
        "# # setup the figure\n",
        "# plt.figure(figsize = (20,20))\n",
        "\n",
        "# for i in range(n):\n",
        "#   ax = plt.subplot(5,5,i+1)\n",
        "#   plt.title(classes[np.where(y[i] == 1)[0][0]])\n",
        "#   plt.imshow(X[i])"
      ],
      "metadata": {
        "id": "xsrCs3pH6hkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrr = ReduceLROnPlateau(monitor = 'val_acc',factor = .01 , patience = 3 , min_lr = 1e-5 , verbose = 1)\n",
        "# prepare callbacks\n",
        "EarlyStop = EarlyStopping(monitor = 'val_loss', patience = 10 , restore_best_weights = True)\n"
      ],
      "metadata": {
        "id": "OhoC7Lbp6hnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "learn_rate = .001\n",
        "sgd = SGD(learning_rate = learn_rate , momentum = .9 , nesterov = False)\n",
        "adam = Adam(learning_rate = learn_rate , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = None , amsgrad = False)\n"
      ],
      "metadata": {
        "id": "ncLx7NLm6hpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Io3mMQN6hsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction by help of pretrained models\n",
        "\n"
      ],
      "metadata": {
        "id": "9HH1M0p5NDb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extrract features from the dataset by a given pretrained mode\n",
        "img_size = (250,250,3)\n",
        "\n",
        "def get_features(mode_name , model_preprocessor , input_size , data):\n",
        "  input_layer = Input(input_size)\n",
        "  preprocessor = Lambda(model_preprocessor)(input_layer)\n",
        "  base_model = mode_name(weights = 'imagenet' , include_top = False , input_shape = input_size)(preprocessor)\n",
        "  avg  = GlobalAveragePooling2D()(base_model)\n",
        "  feature_extractor = Model(inputs = input_layer , outputs = avg)\n",
        "\n",
        "  # Extract feature\n",
        "  feature_maps = feature_extractor.predict(data,verbose = 1)\n",
        "  print('Feature maps shape : ',feature_maps.shape)\n",
        "  return feature_maps"
      ],
      "metadata": {
        "id": "q6o7HA5O6hvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features using InceptionV3\n",
        "from keras.applications.inception_v3 import InceptionV3 , preprocess_input\n",
        "inception_preprocessor = preprocess_input\n",
        "inception_features = get_features(InceptionV3 , inception_preprocessor , img_size , X )"
      ],
      "metadata": {
        "id": "PbQxx8LI6hyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract using Xception\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "xception_preprocessor =  preprocess_input\n",
        "xception_features = get_features(Xception , xception_preprocessor , img_size , X)\n"
      ],
      "metadata": {
        "id": "ZV_gJ5bY6h01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features using InceptionResNetV2\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2 , preprocess_input\n",
        "inc_resnet_preprocessor = preprocess_input\n",
        "inc_resnet_features = get_features(InceptionResNetV2 , inc_resnet_preprocessor , img_size , X)"
      ],
      "metadata": {
        "id": "CsbGrTrb6h37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features using NASNetLarge\n",
        "from keras.applications.nasnet import NASNetLarge , preprocess_input\n",
        "nasnet_preprocessor = preprocess_input\n",
        "nasnet_features = get_features(NASNetLarge , nasnet_preprocessor,img_size , X)"
      ],
      "metadata": {
        "id": "Ui6wS69rQu-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X \n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "TX1Bx-N-QvBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combination of features"
      ],
      "metadata": {
        "id": "l-pPRI1hSjWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating final featuremap by combining all extracted features\n",
        "final_features  = np.concatenate([inception_features,xception_features,nasnet_features,inc_resnet_features,],axis = -1)\n",
        "print('Final feature maps shape' , final_features.shape)"
      ],
      "metadata": {
        "id": "qQ56HOvrQvE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Input Layer with 0.7 Dropout"
      ],
      "metadata": {
        "id": "G1gqOhy7SpZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dropout(0,7,input_shape = (final_features.shape[1],)))\n",
        "model.add(Dense(n_classes,activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = adam,loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "# Training the model...............\n",
        "history = model.fit(final_features,y,batch_size = batch_size , epochs = epochs , validation_split = 0.2 , callbacks = [lrr,EarlyStop])\n"
      ],
      "metadata": {
        "id": "48dhGul2SAe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting to free up ram memory\n",
        "\n",
        "del inception_features\n",
        "del xception_features\n",
        "del nasnet_features\n",
        "del inc_resnet_features\n",
        "del final_features\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "VM6D7NWMSAh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuction to read images from test directory \n",
        "from __future__ import annotations\n",
        "def images_to_array_test(test_path, img_size = (250,250,3)):\n",
        "  test_filenames = [test_path+fname for fname in os.listdir(test_path)]\n",
        "\n",
        "  data_size = len(test_filenames)\n",
        "  images = np.zeros([data_size , img_size[0] , img_size[1],3],dtype = np.uint8)\n",
        "\n",
        "  for ix,img_dir in enumerate(tqdm(test_filenames)):\n",
        "    img = load_img(img_dir, target_size = img_size)\n",
        "    images[ix] = img\n",
        "    del img\n",
        "  print('Output Datasize : ',images.shape)\n",
        "  return images\n",
        "test_data = images_to_array_test('/content/drive/MyDrive/Data/dog-breed-identification/test/',)"
      ],
      "metadata": {
        "id": "smW1F-LHSAk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from test dataset\n",
        "def extract_features(data):\n",
        "  inception_features = get_features(InceptionV3 , inception_preprocessor , img_size , data)\n",
        "  xception_features = get_features(Xception,xception_preprocessor , img_size , data)\n",
        "  nasnet_features = get_features(NASNetLarge,nasnet_preprocessor , img_size , data)\n",
        "  inc_resnet_features = get_features(InceptionResNetV2 , inc_resnet_preprocessor , img_size , data)\n",
        "\n",
        "  final_features = np.concatenate([inception_features , xception_features , nasnet_features , inc_resnet_features],axis = -1)\n",
        "\n",
        "  print('Final feature maps shape' , final_features.shape)\n",
        "\n",
        "  return final_features\n",
        "\n",
        "test_features = extract_features(test_data)\n"
      ],
      "metadata": {
        "id": "eqH5RJVqSAnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test labels given test data features\n",
        "pred  = model.predict(test_features)\n"
      ],
      "metadata": {
        "id": "JyRGT379SAqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First prediction\n",
        "print(pred[0])\n",
        "print(f\"Max value (probability of prediction): {np.max(pred[0])}\")\n",
        "print(f\"Sum: {np.sum(pred[0])}\")\n",
        "print(f\"Max index: {np.argmax(pred[0])}\")\n",
        "print(f\"Predicted Label: {classes[np.argmax(pred[0])]}\")"
      ],
      "metadata": {
        "id": "ji2CwJkHXJki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}